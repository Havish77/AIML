{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Havish77/AIML/blob/main/the_saga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZlIGMvKtyFC-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG99wlDayJ6s",
        "outputId": "95d4f290-b924-495c-943d-f54fdc126e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 590 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_2 = '/content/drive/MyDrive/the saga'\n",
        "ds_train_ = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_2,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[150, 150],\n",
        "    interpolation='nearest',\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Calculate the split sizes\n",
        "total_batches = len(ds_train_)\n",
        "train_split = int(0.96 * total_batches)  # 90% for training\n",
        "\n",
        "# Create training and validation subsets\n",
        "ds_train = ds_train_.take(train_split)  # First 90%\n",
        "ds_valid = ds_train_.skip(train_split)  # Remaining 10%\n",
        "\n",
        "# Optional: Prefetch for performance\n",
        "ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_valid = ds_valid.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "data_train = (\n",
        "    ds_train\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "\n",
        "data_valid = (\n",
        "    ds_valid\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rzanCK1yOEQ",
        "outputId": "483b28e8-0d1c-449e-bc28-7cb0eedbc983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.6272 - loss: 0.9118 - val_accuracy: 0.5714 - val_loss: 0.7036\n",
            "Epoch 2/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 106ms/step - accuracy: 0.6710 - loss: 0.7655 - val_accuracy: 0.7143 - val_loss: 0.6619\n",
            "Epoch 3/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.8414 - loss: 0.3979 - val_accuracy: 1.0000 - val_loss: 0.6462\n",
            "Epoch 4/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9103 - loss: 0.3041 - val_accuracy: 0.7857 - val_loss: 0.6291\n",
            "Epoch 5/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9603 - loss: 0.1793 - val_accuracy: 1.0000 - val_loss: 0.6069\n",
            "Epoch 6/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9644 - loss: 0.1122 - val_accuracy: 0.8571 - val_loss: 0.5692\n",
            "Epoch 7/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9760 - loss: 0.0837 - val_accuracy: 1.0000 - val_loss: 0.5195\n",
            "Epoch 8/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9738 - loss: 0.0850 - val_accuracy: 1.0000 - val_loss: 0.4711\n",
            "Epoch 9/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9874 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.4929\n",
            "Epoch 10/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.9927 - loss: 0.0351 - val_accuracy: 0.9286 - val_loss: 0.4715\n",
            "Epoch 11/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.9881 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.4034\n",
            "Epoch 12/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.9975 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.3602\n",
            "Epoch 13/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9929 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.3279\n",
            "Epoch 14/14\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9972 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.3149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784d8441b250>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model_2 = tf.keras.Sequential()\n",
        "# Convolutional layers\n",
        "model_2.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=(150,150, 3)))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_2.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model_2.add(tf.keras.layers.Flatten())\n",
        "model_2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dropout(0.5))\n",
        "model_2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dropout(0.3))\n",
        "model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(data_train,validation_data=data_valid,epochs=14,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O6IpubIUyQh5"
      },
      "outputs": [],
      "source": [
        "model_2.save('the_saga_final.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "3nLkUuwbyVeV",
        "collapsed": true,
        "outputId": "d7447226-06b1-48e0-85b1-8fef21ed6e6e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (224, 224, 3) where an element of shape (150, 150, 3) was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (224, 224, 3) where an element of shape (150, 150, 3) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-94e5ead62a34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_tf_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (224, 224, 3) where an element of shape (150, 150, 3) was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (224, 224, 3) where an element of shape (150, 150, 3) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import numpy as np\n",
        "\n",
        "# Custom Dataset Class\n",
        "class TestImageDataset:\n",
        "    def __init__(self, image_paths, transform=None):  # Corrected __init__ method\n",
        "        self.image_paths = [path for path in image_paths if self.is_valid_image(path)]\n",
        "        self.transform = transform\n",
        "\n",
        "    def is_valid_image(self, img_path):\n",
        "        try:\n",
        "            Image.open(img_path).convert(\"RGB\")\n",
        "            return True\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Skipping invalid image: {img_path}\")\n",
        "            return False\n",
        "\n",
        "    def __len__(self):  # Corrected __len__ method\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):  # Corrected __getitem__ method\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = keras_image.load_img(img_path, target_size=(224, 224))  # Adjust target size as needed\n",
        "        image_array = keras_image.img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image_array = self.transform(image_array)\n",
        "\n",
        "        return image_array, os.path.basename(img_path)\n",
        "\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Test_Images'\n",
        "image_paths = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path)]\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset = TestImageDataset(image_paths)\n",
        "\n",
        "# Convert to TensorFlow Dataset\n",
        "def generator():\n",
        "    for idx in range(len(test_dataset)):\n",
        "        yield test_dataset[idx]\n",
        "\n",
        "test_tf_dataset = tf.data.Dataset.from_generator(\n",
        "    generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(150, 150, 3), dtype=tf.float32),  # Adjust shape as needed\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    )\n",
        ").batch(32)\n",
        "\n",
        "# Load your trained model\n",
        "#model_path = 'C:/Users/ponmu/OneDrive/Desktop/aiml_ps/my_model.keras'\n",
        "#model = load_model(model_path)\n",
        "# Evaluate the model and make predictions\n",
        "predictions = []\n",
        "\n",
        "for batch_images, filenames in test_tf_dataset:\n",
        "    outputs = model_2(batch_images, training=False)\n",
        "    for filename, output in zip(filenames.numpy(), outputs.numpy()):\n",
        "        label = 1 if output >= 0.5 else 0  # Sigmoid output for binary classification\n",
        "        label_str = 'Real' if label == 1 else 'AI'\n",
        "        predictions.append((filename.decode(\"utf-8\"), label_str))\n",
        "\n",
        "# Print predictions\n",
        "for prediction in predictions:\n",
        "    print(prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjJa3VjyycLo"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "processed_predictions = [(\"image_\" + str(int(filename.split('_')[1].split('.')[0])), label) for filename, label in predictions]\n",
        "processed_predictions.sort()\n",
        "\n",
        "\n",
        "# Save to CSV file\n",
        "csv_path = 'img.csv'  # Save path can be adjusted\n",
        "with open(csv_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Id', 'Label'])  # Write header\n",
        "    writer.writerows(processed_predictions)  # Write data\n",
        "\n",
        "# Print CSV location\n",
        "print(f\"Predictions saved to: {csv_path}\")\n",
        "\n",
        "# Print predictions for confirmation\n",
        "for prediction in processed_predictions:\n",
        "    print(prediction)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "11a6_PYVVCInQpUqRboA2fJf1dWR1_zBC",
      "authorship_tag": "ABX9TyPdCNnqkW+r1ABS3lfhb4vV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}